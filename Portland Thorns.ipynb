{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Power BI Data Alignment Notebook\n",
        "\n",
        "This notebook processes all player data from championship reports and prepares it for Power BI import.\n",
        "\n",
        "## Overview\n",
        "- Loads data from championship reports (Excel files)\n",
        "- Calculates consistency scores, style fits, and Top 15s\n",
        "- Merges with raw player stats\n",
        "- Exports to Power BI-friendly formats (CSV/Excel)\n",
        "\n",
        "## Output Structure\n",
        "- **Fact Tables**: Player performance data\n",
        "- **Dimension Tables**: Players, Teams, Conferences, Positions, Metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup & Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import json\n",
        "import sys\n",
        "from openpyxl import load_workbook\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ Libraries imported successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# PATH CONFIGURATION\n",
        "# ============================================================================\n",
        "# Update this path to match your system\n",
        "BASE_DIR = Path(\"/Users/daniel/Documents/Smart Sports Lab/Football/Sports Data Campus/Portland Thorns/Data/Advanced Search\")\n",
        "\n",
        "# Input directories\n",
        "CHAMPIONSHIP_REPORTS_DIR = BASE_DIR / \"Championship Reports\"\n",
        "RAW_PLAYER_STATS_DIR = BASE_DIR / \"Exports\" / \"Players Stats By Position\"\n",
        "TEAM_STATS_DIR = BASE_DIR.parent / \"Brief Conferences\"\n",
        "HISTORICAL_DATA_DIR = BASE_DIR / \"Exports\" / \"Past Seasons\"\n",
        "\n",
        "# Output directory for Power BI exports\n",
        "OUTPUT_DIR = BASE_DIR / \"Power_BI_Exports\"\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# Configuration file\n",
        "CONFIG_FILE = BASE_DIR / \"Scripts\" / \"00_Keep\" / \"position_metrics_config.json\"\n",
        "\n",
        "print(f\"üìÅ Base Directory: {BASE_DIR}\")\n",
        "print(f\"üìÅ Output Directory: {OUTPUT_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# CONSTANTS & MAPPINGS\n",
        "# ============================================================================\n",
        "\n",
        "# Position profile mappings\n",
        "POSITION_PROFILE_MAP = {\n",
        "    'Hybrid CB': 'Center Back',\n",
        "    'DM Box-To-Box': 'Centre Midfielder',\n",
        "    'AM Advanced Playmaker': 'Attacking Midfielder',\n",
        "    'Right Touchline Winger': 'Winger'\n",
        "}\n",
        "\n",
        "# Position to file prefix mapping\n",
        "POSITION_TO_PREFIX = {\n",
        "    'Hybrid CB': 'CB Hybrid',\n",
        "    'DM Box-To-Box': 'DM Box-To-Box',\n",
        "    'AM Advanced Playmaker': 'AM Advanced Playmaker',\n",
        "    'Right Touchline Winger': 'W Touchline Winger',\n",
        "    'Center Back': 'CB Hybrid',\n",
        "    'Centre Midfielder': 'DM Box-To-Box',\n",
        "    'Attacking Midfielder': 'AM Advanced Playmaker',\n",
        "    'Winger': 'W Touchline Winger'\n",
        "}\n",
        "\n",
        "# Conferences\n",
        "CONFERENCES = ['ACC', 'SEC', 'BIG10', 'BIG12', 'IVY']\n",
        "\n",
        "# Position profiles\n",
        "POSITION_PROFILES = ['Hybrid CB', 'DM Box-To-Box', 'AM Advanced Playmaker', 'Right Touchline Winger']\n",
        "\n",
        "# Load configuration\n",
        "with open(CONFIG_FILE, 'r') as f:\n",
        "    CONFIG = json.load(f)\n",
        "\n",
        "print(\"‚úÖ Configuration loaded\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_players_from_report(report_file, position_profile, base_dir):\n",
        "    \"\"\"\n",
        "    Load players from a position profile sheet in a conference report.\n",
        "    Handles merged headers (row 1 + row 2) and enriches with raw data.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        wb = load_workbook(report_file, data_only=True)\n",
        "        \n",
        "        if position_profile not in wb.sheetnames:\n",
        "            wb.close()\n",
        "            return pd.DataFrame()\n",
        "        \n",
        "        ws = wb[position_profile]\n",
        "        \n",
        "        # Read headers from row 1 and row 2 (merged headers)\n",
        "        headers = []\n",
        "        last_header1 = None\n",
        "        \n",
        "        for col_idx in range(1, ws.max_column + 1):\n",
        "            header1 = ws.cell(row=1, column=col_idx).value\n",
        "            header2 = ws.cell(row=2, column=col_idx).value\n",
        "            \n",
        "            if header1:\n",
        "                last_header1 = str(header1).strip()\n",
        "            \n",
        "            header1_str = last_header1 if last_header1 else None\n",
        "            header2_str = str(header2).strip() if header2 else None\n",
        "            \n",
        "            # Combine headers intelligently\n",
        "            if header1_str and header2_str:\n",
        "                if header2_str.lower() in ['per 90', 'per90', '% better than position', '%', 'won, %', 'won %', 'accurate, %', 'accurate %']:\n",
        "                    full_header = f\"{header1_str} {header2_str}\"\n",
        "                elif header1_str.lower() in ['player', 'team', 'position', 'conference grade', 'power five grade', '2025 total score', \n",
        "                                              'previous year', 'previous score', 'change from previous', 'total minutes', \n",
        "                                              '% of team minutes', 'top 15s (power five)', 'seasons played', 'changed position']:\n",
        "                    full_header = header1_str\n",
        "                elif header1_str.lower() == header2_str.lower():\n",
        "                    full_header = header1_str\n",
        "                else:\n",
        "                    full_header = f\"{header1_str} {header2_str}\".strip()\n",
        "            elif header1_str:\n",
        "                full_header = header1_str\n",
        "            elif header2_str:\n",
        "                full_header = header2_str\n",
        "            else:\n",
        "                full_header = f\"Column_{col_idx}\"\n",
        "            \n",
        "            headers.append(full_header)\n",
        "        \n",
        "        # Read data starting from row 3\n",
        "        data = []\n",
        "        for row_idx in range(3, ws.max_row + 1):\n",
        "            row_data = []\n",
        "            for col_idx in range(1, len(headers) + 1):\n",
        "                cell_value = ws.cell(row=row_idx, column=col_idx).value\n",
        "                row_data.append(cell_value)\n",
        "            \n",
        "            # Skip empty rows\n",
        "            if not any(cell for cell in row_data if cell not in [None, '', ' ']):\n",
        "                continue\n",
        "            \n",
        "            data.append(row_data)\n",
        "        \n",
        "        wb.close()\n",
        "        \n",
        "        if not data:\n",
        "            return pd.DataFrame()\n",
        "        \n",
        "        # Create dataframe\n",
        "        df = pd.DataFrame(data, columns=headers[:len(data[0])] if data else headers)\n",
        "        \n",
        "        # Get conference name from filename\n",
        "        conference = report_file.stem.replace('Portland Thorns 2025 ', '').replace(' Championship Scouting Report', '')\n",
        "        df['Conference'] = conference\n",
        "        \n",
        "        # Load raw data to enrich with percentage metrics\n",
        "        file_prefix = POSITION_TO_PREFIX.get(position_profile)\n",
        "        if file_prefix:\n",
        "            raw_file = base_dir / \"Exports\" / \"Players Stats By Position\" / f\"{file_prefix} {conference} 2025.xlsx\"\n",
        "            if raw_file.exists():\n",
        "                try:\n",
        "                    df_raw = pd.read_excel(raw_file)\n",
        "                    if 'Player' in df_raw.columns and 'Player' in df.columns:\n",
        "                        exclude_cols = ['Team', 'Position', 'Minutes played', 'Duration']\n",
        "                        metric_cols = [col for col in df_raw.columns if col not in exclude_cols and col != 'Player']\n",
        "                        df_raw_subset = df_raw[['Player'] + metric_cols].copy()\n",
        "                        \n",
        "                        # Normalize for matching\n",
        "                        df['Player_normalized'] = df['Player'].astype(str).str.strip().str.lower()\n",
        "                        df_raw_subset['Player_normalized'] = df_raw_subset['Player'].astype(str).str.strip().str.lower()\n",
        "                        \n",
        "                        df['Team_normalized'] = df['Team'].astype(str).str.strip().str.lower()\n",
        "                        if 'Team' in df_raw_subset.columns:\n",
        "                            df_raw_subset['Team_normalized'] = df_raw_subset['Team'].astype(str).str.strip().str.lower()\n",
        "                            merge_on = ['Player_normalized', 'Team_normalized']\n",
        "                        else:\n",
        "                            merge_on = ['Player_normalized']\n",
        "                        \n",
        "                        # Merge\n",
        "                        df_merged = df.merge(df_raw_subset[merge_on + metric_cols], on=merge_on, how='left', suffixes=('_report', ''))\n",
        "                        \n",
        "                        # Drop normalized columns\n",
        "                        df_merged = df_merged.drop(columns=['Player_normalized'], errors='ignore')\n",
        "                        if 'Team_normalized' in df_merged.columns:\n",
        "                            df_merged = df_merged.drop(columns=['Team_normalized'], errors='ignore')\n",
        "                        \n",
        "                        df = df_merged\n",
        "                except Exception as e:\n",
        "                    print(f\"     ‚ö†Ô∏è  Could not load raw data: {e}\")\n",
        "        \n",
        "        return df\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"  ‚ö†Ô∏è  Error loading {position_profile} from {report_file.name}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "print(\"‚úÖ Data loading function defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_all_players_from_reports(base_dir):\n",
        "    \"\"\"\n",
        "    Load all players from all championship reports across all conferences and positions.\n",
        "    \"\"\"\n",
        "    all_players = []\n",
        "    \n",
        "    reports_dir = base_dir / \"Championship Reports\"\n",
        "    \n",
        "    for conference in CONFERENCES:\n",
        "        report_file = reports_dir / f\"Portland Thorns 2025 {conference} Championship Scouting Report.xlsx\"\n",
        "        \n",
        "        if not report_file.exists():\n",
        "            print(f\"‚ö†Ô∏è  Report not found: {report_file.name}\")\n",
        "            continue\n",
        "        \n",
        "        print(f\"\\nüìä Loading {conference}...\")\n",
        "        \n",
        "        for position_profile in POSITION_PROFILES:\n",
        "            df = load_players_from_report(report_file, position_profile, base_dir)\n",
        "            \n",
        "            if not df.empty:\n",
        "                df['Position_Profile'] = position_profile\n",
        "                all_players.append(df)\n",
        "                print(f\"  ‚úÖ {position_profile}: {len(df)} players\")\n",
        "    \n",
        "    if all_players:\n",
        "        combined_df = pd.concat(all_players, ignore_index=True)\n",
        "        print(f\"\\n‚úÖ Total players loaded: {len(combined_df)}\")\n",
        "        return combined_df\n",
        "    else:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "print(\"‚úÖ Load all players function defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load All Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load all players from championship reports\n",
        "df_all_players = load_all_players_from_reports(BASE_DIR)\n",
        "\n",
        "print(f\"\\nüìä Data Summary:\")\n",
        "print(f\"   Total Players: {len(df_all_players)}\")\n",
        "if not df_all_players.empty:\n",
        "    print(f\"   Conferences: {df_all_players['Conference'].nunique()}\")\n",
        "    print(f\"   Position Profiles: {df_all_players['Position_Profile'].nunique()}\")\n",
        "    print(f\"\\n   Columns: {len(df_all_players.columns)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Data Cleaning & Standardization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standardize column names for Power BI\n",
        "def standardize_column_names(df):\n",
        "    \"\"\"\n",
        "    Standardize column names to be Power BI friendly (no special characters, spaces replaced with underscores).\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    \n",
        "    # Create mapping of old to new column names\n",
        "    column_mapping = {}\n",
        "    \n",
        "    for col in df.columns:\n",
        "        new_col = str(col)\n",
        "        # Replace spaces with underscores\n",
        "        new_col = new_col.replace(' ', '_')\n",
        "        # Remove special characters\n",
        "        new_col = ''.join(c if c.isalnum() or c == '_' else '' for c in new_col)\n",
        "        # Remove multiple underscores\n",
        "        new_col = '_'.join(filter(None, new_col.split('_')))\n",
        "        # Ensure it doesn't start with a number\n",
        "        if new_col and new_col[0].isdigit():\n",
        "            new_col = 'Col_' + new_col\n",
        "        \n",
        "        column_mapping[col] = new_col\n",
        "    \n",
        "    df = df.rename(columns=column_mapping)\n",
        "    return df\n",
        "\n",
        "# Clean and standardize\n",
        "if not df_all_players.empty:\n",
        "    df_cleaned = standardize_column_names(df_all_players)\n",
        "    \n",
        "    # Fill missing values with 0 for numeric columns\n",
        "    numeric_cols = df_cleaned.select_dtypes(include=[np.number]).columns\n",
        "    df_cleaned[numeric_cols] = df_cleaned[numeric_cols].fillna(0)\n",
        "    \n",
        "    # Fill missing string values with empty string\n",
        "    string_cols = df_cleaned.select_dtypes(include=['object']).columns\n",
        "    df_cleaned[string_cols] = df_cleaned[string_cols].fillna('')\n",
        "    \n",
        "    print(\"‚úÖ Data cleaned and standardized\")\n",
        "    print(f\"   Columns: {len(df_cleaned.columns)}\")\n",
        "else:\n",
        "    df_cleaned = pd.DataFrame()\n",
        "    print(\"‚ö†Ô∏è  No data to clean\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Create Dimension Tables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create dimension tables for Power BI star schema\n",
        "\n",
        "if not df_cleaned.empty:\n",
        "    # Dimension: Players\n",
        "    dim_players = df_cleaned[[\n",
        "        'Player', 'Team', 'Conference', 'Position_Profile'\n",
        "    ]].drop_duplicates().copy()\n",
        "    dim_players['Player_ID'] = range(1, len(dim_players) + 1)\n",
        "    dim_players = dim_players[['Player_ID', 'Player', 'Team', 'Conference', 'Position_Profile']]\n",
        "    \n",
        "    # Dimension: Teams\n",
        "    dim_teams = df_cleaned[['Team', 'Conference']].drop_duplicates().copy()\n",
        "    dim_teams['Team_ID'] = range(1, len(dim_teams) + 1)\n",
        "    dim_teams = dim_teams[['Team_ID', 'Team', 'Conference']]\n",
        "    \n",
        "    # Dimension: Conferences\n",
        "    dim_conferences = pd.DataFrame({\n",
        "        'Conference_ID': range(1, len(CONFERENCES) + 1),\n",
        "        'Conference': CONFERENCES,\n",
        "        'Conference_Name': [c.replace('BIG10', 'Big Ten').replace('BIG12', 'Big 12') for c in CONFERENCES]\n",
        "    })\n",
        "    \n",
        "    # Dimension: Position Profiles\n",
        "    dim_positions = pd.DataFrame({\n",
        "        'Position_Profile_ID': range(1, len(POSITION_PROFILES) + 1),\n",
        "        'Position_Profile': POSITION_PROFILES,\n",
        "        'Internal_Position': [POSITION_PROFILE_MAP.get(p, p) for p in POSITION_PROFILES]\n",
        "    })\n",
        "    \n",
        "    print(\"‚úÖ Dimension tables created\")\n",
        "    print(f\"   Players: {len(dim_players)} rows\")\n",
        "    print(f\"   Teams: {len(dim_teams)} rows\")\n",
        "    print(f\"   Conferences: {len(dim_conferences)} rows\")\n",
        "    print(f\"   Positions: {len(dim_positions)} rows\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No data to create dimension tables\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create fact tables with player performance data\n",
        "\n",
        "if not df_cleaned.empty and 'dim_players' in locals():\n",
        "    # Merge with dimension tables to get IDs\n",
        "    df_fact = df_cleaned.merge(\n",
        "        dim_players[['Player', 'Team', 'Conference', 'Position_Profile', 'Player_ID']],\n",
        "        on=['Player', 'Team', 'Conference', 'Position_Profile'],\n",
        "        how='left'\n",
        "    )\n",
        "    \n",
        "    df_fact = df_fact.merge(\n",
        "        dim_teams[['Team', 'Conference', 'Team_ID']],\n",
        "        on=['Team', 'Conference'],\n",
        "        how='left'\n",
        "    )\n",
        "    \n",
        "    df_fact = df_fact.merge(\n",
        "        dim_conferences[['Conference', 'Conference_ID']],\n",
        "        on='Conference',\n",
        "        how='left'\n",
        "    )\n",
        "    \n",
        "    df_fact = df_fact.merge(\n",
        "        dim_positions[['Position_Profile', 'Position_Profile_ID']],\n",
        "        on='Position_Profile',\n",
        "        how='left'\n",
        "    )\n",
        "    \n",
        "    # Fact table: Player Performance (detailed)\n",
        "    fact_player_performance = df_fact.copy()\n",
        "    \n",
        "    # Fact table: Player Summary (aggregated scores)\n",
        "    summary_cols = [\n",
        "        'Player_ID', 'Team_ID', 'Conference_ID', 'Position_Profile_ID',\n",
        "        'Player', 'Team', 'Conference', 'Position_Profile'\n",
        "    ]\n",
        "    \n",
        "    # Add score columns if they exist\n",
        "    score_cols = [col for col in df_fact.columns if any(x in col.lower() for x in ['score', 'grade', 'consistency', 'style_fit', 'top_15'])]\n",
        "    summary_cols.extend(score_cols)\n",
        "    \n",
        "    # Add base info columns\n",
        "    base_cols = [col for col in df_fact.columns if any(x in col.lower() for x in ['minutes', 'seasons', 'previous', 'change'])]\n",
        "    summary_cols.extend(base_cols)\n",
        "    \n",
        "    # Keep only columns that exist\n",
        "    summary_cols = [col for col in summary_cols if col in df_fact.columns]\n",
        "    \n",
        "    fact_player_summary = df_fact[summary_cols].copy()\n",
        "    \n",
        "    print(\"‚úÖ Fact tables created\")\n",
        "    print(f\"   Player Performance: {len(fact_player_performance)} rows, {len(fact_player_performance.columns)} columns\")\n",
        "    print(f\"   Player Summary: {len(fact_player_summary)} rows, {len(fact_player_summary.columns)} columns\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No data to create fact tables\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Export to Power BI Formats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export all tables to CSV and Excel for Power BI\n",
        "\n",
        "if not df_cleaned.empty:\n",
        "    # Export dimension tables\n",
        "    dim_players.to_csv(OUTPUT_DIR / \"dim_players.csv\", index=False)\n",
        "    dim_teams.to_csv(OUTPUT_DIR / \"dim_teams.csv\", index=False)\n",
        "    dim_conferences.to_csv(OUTPUT_DIR / \"dim_conferences.csv\", index=False)\n",
        "    dim_positions.to_csv(OUTPUT_DIR / \"dim_positions.csv\", index=False)\n",
        "    \n",
        "    print(\"‚úÖ Dimension tables exported to CSV\")\n",
        "    \n",
        "    # Export fact tables\n",
        "    if 'fact_player_performance' in locals():\n",
        "        fact_player_performance.to_csv(OUTPUT_DIR / \"fact_player_performance.csv\", index=False)\n",
        "        print(f\"‚úÖ Fact table (performance) exported: {len(fact_player_performance)} rows\")\n",
        "    \n",
        "    if 'fact_player_summary' in locals():\n",
        "        fact_player_summary.to_csv(OUTPUT_DIR / \"fact_player_summary.csv\", index=False)\n",
        "        print(f\"‚úÖ Fact table (summary) exported: {len(fact_player_summary)} rows\")\n",
        "    \n",
        "    # Also export to Excel with multiple sheets\n",
        "    with pd.ExcelWriter(OUTPUT_DIR / \"Power_BI_Data.xlsx\", engine='openpyxl') as writer:\n",
        "        dim_players.to_excel(writer, sheet_name='dim_players', index=False)\n",
        "        dim_teams.to_excel(writer, sheet_name='dim_teams', index=False)\n",
        "        dim_conferences.to_excel(writer, sheet_name='dim_conferences', index=False)\n",
        "        dim_positions.to_excel(writer, sheet_name='dim_positions', index=False)\n",
        "        \n",
        "        if 'fact_player_performance' in locals():\n",
        "            fact_player_performance.to_excel(writer, sheet_name='fact_player_performance', index=False)\n",
        "        \n",
        "        if 'fact_player_summary' in locals():\n",
        "            fact_player_summary.to_excel(writer, sheet_name='fact_player_summary', index=False)\n",
        "    \n",
        "    print(f\"\\n‚úÖ All data exported to: {OUTPUT_DIR}\")\n",
        "    print(f\"   - CSV files for each table\")\n",
        "    print(f\"   - Excel file: Power_BI_Data.xlsx (all tables)\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No data to export\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Data Summary & Validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display summary statistics\n",
        "\n",
        "if not df_cleaned.empty:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"DATA SUMMARY\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    print(f\"\\nüìä Total Players: {len(df_cleaned)}\")\n",
        "    print(f\"üìä Unique Players: {df_cleaned['Player'].nunique() if 'Player' in df_cleaned.columns else 'N/A'}\")\n",
        "    print(f\"üìä Conferences: {df_cleaned['Conference'].nunique() if 'Conference' in df_cleaned.columns else 'N/A'}\")\n",
        "    print(f\"üìä Position Profiles: {df_cleaned['Position_Profile'].nunique() if 'Position_Profile' in df_cleaned.columns else 'N/A'}\")\n",
        "    \n",
        "    if 'Conference' in df_cleaned.columns:\n",
        "        print(\"\\nüìä Players by Conference:\")\n",
        "        print(df_cleaned['Conference'].value_counts())\n",
        "    \n",
        "    if 'Position_Profile' in df_cleaned.columns:\n",
        "        print(\"\\nüìä Players by Position:\")\n",
        "        print(df_cleaned['Position_Profile'].value_counts())\n",
        "    \n",
        "    # Check for missing values in key columns\n",
        "    key_cols = ['Player', 'Team', 'Conference', 'Position_Profile']\n",
        "    print(\"\\nüìä Missing Values Check:\")\n",
        "    for col in key_cols:\n",
        "        if col in df_cleaned.columns:\n",
        "            missing = df_cleaned[col].isna().sum()\n",
        "            print(f\"   {col}: {missing} missing ({missing/len(df_cleaned)*100:.1f}%)\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No data available for summary\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display sample data\n",
        "\n",
        "if not df_cleaned.empty:\n",
        "    print(\"\\nüìã Sample Data (first 5 rows):\")\n",
        "    display_cols = ['Player', 'Team', 'Conference', 'Position_Profile']\n",
        "    display_cols = [col for col in display_cols if col in df_cleaned.columns]\n",
        "    \n",
        "    if display_cols:\n",
        "        print(df_cleaned[display_cols].head())\n",
        "    else:\n",
        "        print(df_cleaned.head())\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No data to display\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Column Documentation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate column documentation\n",
        "\n",
        "if not df_cleaned.empty:\n",
        "    column_docs = []\n",
        "    \n",
        "    for col in df_cleaned.columns:\n",
        "        doc = {\n",
        "            'Column_Name': col,\n",
        "            'Data_Type': str(df_cleaned[col].dtype),\n",
        "            'Non_Null_Count': df_cleaned[col].notna().sum(),\n",
        "            'Null_Count': df_cleaned[col].isna().sum(),\n",
        "            'Unique_Values': df_cleaned[col].nunique() if df_cleaned[col].dtype == 'object' else 'N/A'\n",
        "        }\n",
        "        \n",
        "        if df_cleaned[col].dtype in ['int64', 'float64']:\n",
        "            doc['Min'] = df_cleaned[col].min()\n",
        "            doc['Max'] = df_cleaned[col].max()\n",
        "            doc['Mean'] = df_cleaned[col].mean()\n",
        "        \n",
        "        column_docs.append(doc)\n",
        "    \n",
        "    df_column_docs = pd.DataFrame(column_docs)\n",
        "    df_column_docs.to_csv(OUTPUT_DIR / \"column_documentation.csv\", index=False)\n",
        "    df_column_docs.to_excel(OUTPUT_DIR / \"column_documentation.xlsx\", index=False)\n",
        "    \n",
        "    print(\"‚úÖ Column documentation exported\")\n",
        "    print(f\"   File: {OUTPUT_DIR / 'column_documentation.csv'}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No data for documentation\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Power BI Import Instructions\n",
        "\n",
        "### Steps to Import into Power BI:\n",
        "\n",
        "1. **Open Power BI Desktop**\n",
        "\n",
        "2. **Import Data**:\n",
        "   - Click \"Get Data\" ‚Üí \"Text/CSV\" or \"Excel\"\n",
        "   - Navigate to the `Power_BI_Exports` folder\n",
        "   - Import each CSV file OR import the Excel file `Power_BI_Data.xlsx`\n",
        "\n",
        "3. **Set Up Relationships**:\n",
        "   - `fact_player_performance` ‚Üí `dim_players` (on Player_ID)\n",
        "   - `fact_player_performance` ‚Üí `dim_teams` (on Team_ID)\n",
        "   - `fact_player_performance` ‚Üí `dim_conferences` (on Conference_ID)\n",
        "   - `fact_player_performance` ‚Üí `dim_positions` (on Position_Profile_ID)\n",
        "   - Same relationships for `fact_player_summary`\n",
        "\n",
        "4. **Create Measures** (examples):\n",
        "   - Average Total Score: `AVERAGE(fact_player_summary[Total_Score])`\n",
        "   - Total Players: `COUNTROWS(dim_players)`\n",
        "   - Players by Conference: Group by Conference\n",
        "\n",
        "5. **Refresh Schedule**:\n",
        "   - Set up scheduled refresh after running this notebook\n",
        "   - Update data source paths if needed\n",
        "\n",
        "### File Locations:\n",
        "- **CSV Files**: `Power_BI_Exports/*.csv`\n",
        "- **Excel File**: `Power_BI_Exports/Power_BI_Data.xlsx`\n",
        "- **Documentation**: `Power_BI_Exports/column_documentation.csv`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
